{
    "My Behavior": {
        "checkpoints": [
            {
                "steps": 999994,
                "file_path": "results\\MyTestWithNumEnvs1-NewRays\\My Behavior\\My Behavior-999994.onnx",
                "reward": 0.7125000348314643,
                "creation_time": 1684522262.4038153,
                "auxillary_file_paths": [
                    "results\\MyTestWithNumEnvs1-NewRays\\My Behavior\\My Behavior-999994.pt"
                ]
            },
            {
                "steps": 1051069,
                "file_path": "results\\MyTestWithNumEnvs1-NewRays\\My Behavior\\My Behavior-1051069.onnx",
                "reward": 0.8388889299498664,
                "creation_time": 1684522747.716436,
                "auxillary_file_paths": [
                    "results\\MyTestWithNumEnvs1-NewRays\\My Behavior\\My Behavior-1051069.pt"
                ]
            },
            {
                "steps": 1276553,
                "file_path": "results\\MyTestWithNumEnvs1-NewRays\\My Behavior\\My Behavior-1276553.onnx",
                "reward": 0.5692308012109536,
                "creation_time": 1684535311.8677247,
                "auxillary_file_paths": [
                    "results\\MyTestWithNumEnvs1-NewRays\\My Behavior\\My Behavior-1276553.pt"
                ]
            },
            {
                "steps": 1499987,
                "file_path": "results\\MyTestWithNumEnvs1-NewRays\\My Behavior\\My Behavior-1499987.onnx",
                "reward": 1.3083333882192771,
                "creation_time": 1684537657.5395138,
                "auxillary_file_paths": [
                    "results\\MyTestWithNumEnvs1-NewRays\\My Behavior\\My Behavior-1499987.pt"
                ]
            },
            {
                "steps": 1501139,
                "file_path": "results\\MyTestWithNumEnvs1-NewRays\\My Behavior\\My Behavior-1501139.onnx",
                "reward": 1.3083333882192771,
                "creation_time": 1684537666.6488304,
                "auxillary_file_paths": [
                    "results\\MyTestWithNumEnvs1-NewRays\\My Behavior\\My Behavior-1501139.pt"
                ]
            }
        ],
        "final_checkpoint": {
            "steps": 1501139,
            "file_path": "results\\MyTestWithNumEnvs1-NewRays\\My Behavior.onnx",
            "reward": 1.3083333882192771,
            "creation_time": 1684537666.6488304,
            "auxillary_file_paths": [
                "results\\MyTestWithNumEnvs1-NewRays\\My Behavior\\My Behavior-1501139.pt"
            ]
        }
    },
    "metadata": {
        "stats_format_version": "0.3.0",
        "mlagents_version": "0.29.0",
        "torch_version": "1.7.1+cu110"
    }
}